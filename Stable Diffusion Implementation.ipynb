{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd4f0cb-9313-443d-af07-dcd991862400",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "import os\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "from models.diffusion import StableDiffusion\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from transformers import CLIPTokenizer\n",
    "from PIL import Image\n",
    "from utils.model_converter import load_weights_from_ckpt\n",
    "from torch.ao.quantization import QConfig, HistogramObserver, MinMaxObserver\n",
    "\n",
    "\n",
    "prompt = \"A cat is sitting, looking out the window\"\n",
    "uncond_prompt = \"\"  # Also known as negative prompt\n",
    "do_cfg = True\n",
    "cfg_scale = 8  # min: 1, max: 14\n",
    "\n",
    "## IMAGE TO IMAGE\n",
    "\n",
    "# Comment to disable image to image\n",
    "input_image = None\n",
    "image_path = \"./images/dog.jpg\"\n",
    "input_image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "# Higher values means more noise will be added to the input image, so the result will further from the input image.\n",
    "# Lower values means less noise is added to the input image, so output will be closer to the input image.\n",
    "strength = 0.1\n",
    "\n",
    "## SAMPLER\n",
    "num_inference_steps = 50\n",
    "seed = 42\n",
    "model = StableDiffusion(model_type='txt2img')\n",
    "loaded_state_dict = load_weights_from_ckpt('./weights/model/v1-5-pruned-emaonly.ckpt', device='cpu')\n",
    "model.vae.load_state_dict(loaded_state_dict['vae'], strict=True)\n",
    "model.unet.load_state_dict(loaded_state_dict['unet'], strict=True)\n",
    "model.cond_encoder.load_state_dict(loaded_state_dict['cond_encoder'], strict=True)\n",
    "\n",
    "tokenizer = CLIPTokenizer('./weights/tokenizer/tokenizer_vocab.json', merges_file='./weights/tokenizer/tokenizer_merges.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02289d1d-27d7-45e0-b563-1f90cef2cf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import quantize_model\n",
    "quantized_cond_encoder = quantize_model.quantize_cond_encoder(model.cond_encoder, tokenizer=tokenizer)\n",
    "quantized_vae = quantize_model.quantize_vae(model.vae)\n",
    "quantized_unet = quantize_model.quantize_unet(model.unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e77737-610c-4491-811f-981b8510c52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.unet = quantized_unet\n",
    "model.vae = quantized_vae\n",
    "model.cond_encoder = quantized_cond_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af90cdc-1ddd-4d88-a3cb-01c085d698cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "output_image = model.generate(\n",
    "    input_image=None,\n",
    "    img_size=(512, 512),\n",
    "     prompt=\"A cozy mountain cabin at sunrise\",\n",
    "     uncond_promt=uncond_prompt,\n",
    "     do_cfg=do_cfg,\n",
    "     cfg_scale=cfg_scale,\n",
    "     device='cpu',\n",
    "     strength=0.2,\n",
    "     inference_steps=num_inference_steps,\n",
    "     sampler='ddpm',\n",
    "     use_cosine_schedule=False,\n",
    "     seed=seed,\n",
    "     tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56ed1e6-2a57-4ee0-8d6e-4814c70da7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c001a33b-c371-4401-a3f7-b4c5742a4974",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './quantized_model.pth')\n",
    "os.path.getsize('./quantized_model.pth') / (1024 * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc916a40-7884-4c8e-9e5a-cfc6f7512717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "  0%|                                                  | 0/4470 [00:00<?, ?it/s]\n",
      "Step [0/4470] | Loss: 1.16\n",
      "  0%|                                       | 9/4470 [02:49<10:25:56,  8.42s/it]"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "!python3 train.py --device=mps --batch_size 16 --data_dir ./data/sprites/ --save_dir ./checkpoints/ --checkpoint_dir ./checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081c0488-42a8-4ecf-903f-8c776de0e96f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
